{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HW2\n",
    "\n",
    "# all required imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import geopy as gd\n",
    "from geopy.distance import geodesic\n",
    "import os\n",
    "import math\n",
    "import scipy as sp\n",
    "from scipy.stats.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'pickup_latitude'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-ff8b031a9836>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# removing invalid longitude rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpickup_latitude\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m90\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpickup_latitude\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m90\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropoff_latitude\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m90\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   4370\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4371\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4372\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4374\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'pickup_latitude'"
     ]
    }
   ],
   "source": [
    "# Q1. Data Cleaning\n",
    "\n",
    "#feature_set = pd.read_csv(\"\", converters= {}, low_memory=False, parse_dates=[2], infer_datetime_format=True, error_bad_lines=False, warn_bad_lines=True)\n",
    "\n",
    "#reading the training data\n",
    "#train_data = pd.read_csv(\"./Data/train_small.csv\", usecols=range(1,8), low_memory=False, error_bad_lines=False)\n",
    "train_data = pd.read_csv(\"./Data/train_1m.csv\", usecols=range(1,8), low_memory=False, error_bad_lines=False)\n",
    "#train_data = pd.read_csv(\"./Data/train.csv\", nrows=2000, usecols=range(0,8), low_memory=False, error_bad_lines=False)\n",
    "\n",
    "# removing invalid longitude rows\n",
    "train_data = train_data[(train_data.pickup_latitude <= 90)]\n",
    "train_data = train_data[(train_data.pickup_latitude >= -90)]\n",
    "train_data = train_data[(train_data.dropoff_latitude <= 90)]\n",
    "train_data = train_data[(train_data.dropoff_latitude >= -90)]\n",
    "\n",
    "#function to add two new column containing the difference for lat, lon\n",
    "def add_lat_lon_diff(td):\n",
    "        td['abs_diff_longitude'] = (td.dropoff_longitude - td.pickup_longitude).abs()\n",
    "        td['abs_diff_latitude'] = (td.dropoff_latitude - td.pickup_latitude).abs()\n",
    "\n",
    "add_lat_lon_diff(train_data)\n",
    "        \n",
    "#setting invalid dates to NaN\n",
    "train_data['pickup_datetime'] = train_data['pickup_datetime'].apply(pd.to_datetime, errors='coerce')\n",
    "\n",
    "#setting invalid values to NaN\n",
    "float_col = ['fare_amount', 'pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude', 'passenger_count']\n",
    "train_data[float_col] = train_data[float_col].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "#removing the rows containing NaN\n",
    "train_data.dropna()\n",
    "\n",
    "# removing outlier lat lon values\n",
    "train_data = train_data[(train_data.abs_diff_longitude < 5.0) & (train_data.abs_diff_latitude < 5.0)]\n",
    "\n",
    "# removing rows with value = 0 as it is not valid data\n",
    "train_data = train_data[(train_data.pickup_longitude != 0) & (train_data.pickup_latitude != 0) & \n",
    "        (train_data.dropoff_longitude != 0) & (train_data.dropoff_latitude != 0) &\n",
    "        (train_data.passenger_count != 0) & (train_data.fare_amount != 0) &\n",
    "        (train_data.passenger_count <= 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding new features\n",
    "\n",
    "# function to add a new column containing distance between pickpup and dropoff\n",
    "def euclid_distance(row_data):\n",
    "    return (geodesic((row_data.pickup_latitude, row_data.pickup_longitude), (row_data.dropoff_latitude, row_data.dropoff_longitude)).miles)\n",
    "\n",
    "def manhattan_distance(row_data):\n",
    "    #return row_data.abs_diff_longitude + row_data.abs_diff_latitude\n",
    "    hypotenuse = (geodesic((row_data.pickup_latitude, row_data.pickup_longitude), (row_data.dropoff_latitude, row_data.dropoff_longitude)).miles)\n",
    "    sum_of_sides = 2 * math.sqrt((math.pow(hypotenuse, 2)/2))\n",
    "    return sum_of_sides\n",
    "    \n",
    "#get hour:minute format\n",
    "def hour_minute(row_data):\n",
    "    return (row_data.pickup_datetime.hour) #* 100 + (row_data.pickup_datetime.minute)\n",
    "\n",
    "#get day_of_week format\n",
    "def day_of_week(row_data):\n",
    "    return (row_data.pickup_datetime.weekday())\n",
    "\n",
    "def add_new_features(td):\n",
    "    td['euclid_distance'] = td.apply(lambda row: euclid_distance(row), axis=1)\n",
    "    td['distance_travelled'] = td.apply(lambda row: manhattan_distance(row), axis=1)\n",
    "    td['time_of_day'] = td.apply(lambda row: hour_minute(row), axis=1)\n",
    "    td['day_of_week'] = td.apply(lambda row: day_of_week(row), axis=1)\n",
    "\n",
    "add_new_features(train_data)\n",
    "\n",
    "# removing rows with distance < 0.1 miles and more than 3000 miles\n",
    "train_data = train_data[(train_data.distance_travelled > 0.1)]\n",
    "train_data = train_data[(train_data.distance_travelled < 3000)]\n",
    "\n",
    "# adding column for fare_per_km\n",
    "train_data['fare_per_km'] = train_data.fare_amount/train_data.euclid_distance\n",
    "\n",
    "# per km charges more than 50$/km seems wrong data\n",
    "train_data = train_data[train_data.fare_per_km < 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2.a) Pearson Correlation between Euclidean distance of the ride and the taxi fare\n",
    "\n",
    "pearsonr(train_data.euclid_distance, train_data.fare_amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2.b) Pearson Correlation between Time of Day and distance\n",
    "    \n",
    "pearsonr(train_data.distance_travelled, train_data.time_of_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2.c) Pearson Correlation between Time of Day and fare_amount\n",
    "\n",
    "pearsonr(train_data.fare_amount, train_data.time_of_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3. a) Plot between Euclidean distance of the ride and the taxi fare\n",
    "\n",
    "plot = train_data.plot.scatter('euclid_distance', 'fare_amount')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3. b) Plot between Time of Day and distance_travelled\n",
    "\n",
    "plot = train_data.plot.scatter('time_of_day', 'distance_travelled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3. c) Plot between Time of Day and fare_amount\n",
    "\n",
    "plot = train_data.plot.scatter('time_of_day', 'fare_amount')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4. Create an exciting plot of your own using the dataset that you think reveals something very interesting.\n",
    "# Explain what it is, and anything else you learned.\n",
    "\n",
    "# plot of data on weekdays\n",
    "#train_data.groupby(train_data.time_of_day).mean()['fare_per_km'].plot('line')\n",
    "#train_data[\"day_of_week\"].plot.hist(bins=13)\n",
    "train_data.groupby(train_data.day_of_week).mean()['fare_per_km'].plot('bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading test data and adding features which were added to training data\n",
    "\n",
    "\n",
    "test_data = pd.read_csv(\"./Data/test.csv\", usecols=range(0,7), low_memory=False, error_bad_lines=False)\n",
    "test_data['pickup_datetime'] = test_data['pickup_datetime'].apply(pd.to_datetime, errors='coerce')\n",
    "\n",
    "add_new_features(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q6.\n",
    "\n",
    "#training the model\n",
    "\n",
    "def get_basic_training_features(td):\n",
    "    return np.column_stack((td.euclid_distance, np.ones(len(td))))\n",
    "\n",
    "train_x = get_basic_training_features(train_data)\n",
    "train_y = np.array(train_data['fare_amount'])\n",
    "\n",
    "# Linear Regression model initialization\n",
    "linear_regression_basic = LinearRegression()\n",
    "\n",
    "# Training the Linear Regression Model\n",
    "linear_regression_basic.fit(train_x, train_y)\n",
    "print(linear_regression_basic.coef_)\n",
    "\n",
    "# Predict fare_amount for training data to get calculate errors\n",
    "pre_test_x = get_basic_training_features(train_data)\n",
    "pre_test_y = linear_regression_basic.predict(pre_test_x)\n",
    "\n",
    "# Mean squared error and variance\n",
    "print(\"Mean squared error: %.5f\" % mean_squared_error(train_data.fare_amount, pre_test_y))\n",
    "print('Variance : %.5f' % r2_score(train_data.fare_amount, pre_test_y))\n",
    "\n",
    "# Predict fare_amount for actual test data\n",
    "test_x = get_basic_training_features(test_data)\n",
    "test_y = linear_regression_basic.predict(test_x)\n",
    "\n",
    "# write prediction to csv file\n",
    "prediction_output = pd.DataFrame(\n",
    "    {'key': test_data.key, 'fare_amount': test_y},\n",
    "    columns = ['key', 'fare_amount'])\n",
    "prediction_output.to_csv('prediction_with_basic_features.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing data\n",
    "train_data['euclid_distance'] = train_data.euclid_distance / train_data.euclid_distance.max()\n",
    "train_data['time_of_day'] = train_data.time_of_day / train_data.time_of_day.max()\n",
    "train_data['day_of_week'] = train_data.day_of_week / train_data.day_of_week.max()\n",
    "train_data['fare_amount'] = train_data.fare_amount / train_data.fare_amount.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q8.\n",
    "\n",
    "# Training Linear regression with more features\n",
    "\n",
    "def get_advanced_training_features(td):\n",
    "    return np.column_stack((td.euclid_distance, td.time_of_day, td.day_of_week, np.ones(len(td))))\n",
    "\n",
    "train_x = get_advanced_training_features(train_data)\n",
    "train_y = np.array(train_data['fare_amount'])\n",
    "\n",
    "# Linear Regression model initialization\n",
    "linear_regression_adv = LinearRegression()\n",
    "\n",
    "# Training the Linear Regression Model\n",
    "linear_regression_adv.fit(train_x, train_y)\n",
    "print(linear_regression_adv.coef_)\n",
    "\n",
    "# Predict fare_amount for training data to get calculate errors\n",
    "pre_test_x = get_advanced_training_features(train_data)\n",
    "pre_test_y = linear_regression_adv.predict(pre_test_x)\n",
    "\n",
    "# Mean squared error and variance\n",
    "print(\"Mean squared error: %.5f\" % mean_squared_error(train_data.fare_amount, pre_test_y))\n",
    "print('Variance : %.5f' % r2_score(train_data.fare_amount, pre_test_y))\n",
    "\n",
    "# Predict fare_amount\n",
    "test_x = get_advanced_training_features(test_data)\n",
    "test_y = linear_regression_adv.predict(test_x)\n",
    "\n",
    "# write prediction to csv file\n",
    "prediction_output = pd.DataFrame(\n",
    "    {'key': test_data.key, 'fare_amount': test_y},\n",
    "    columns = ['key', 'fare_amount'])\n",
    "prediction_output.to_csv('prediction_with_advanced_features.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q8.\n",
    "\n",
    "# Training KNN with more features\n",
    "\n",
    "def get_advanced_training_features(td):\n",
    "    return np.column_stack((td.euclid_distance, td.time_of_day, td.day_of_week, np.ones(len(td))))\n",
    "\n",
    "train_x = get_advanced_training_features(train_data)\n",
    "train_y = np.array(train_data['fare_amount'])\n",
    "\n",
    "# KNN Regression model initialization\n",
    "knn_regression_adv = KNeighborsRegressor(n_neighbors=200)\n",
    "\n",
    "# Training the KNN Regression Model\n",
    "knn_regression_adv.fit(train_x, train_y)\n",
    "\n",
    "# Predict fare_amount for training data to get calculate errors\n",
    "pre_test_x = get_advanced_training_features(train_data)\n",
    "pre_test_y = knn_regression_adv.predict(pre_test_x)\n",
    "\n",
    "# Mean squared error and variance\n",
    "print(\"Mean squared error: %.5f\" % mean_squared_error(train_data.fare_amount, pre_test_y))\n",
    "print('Variance : %.5f' % r2_score(train_data.fare_amount, pre_test_y))\n",
    "\n",
    "# Predict fare_amount\n",
    "test_x = get_advanced_training_features(test_data)\n",
    "test_y = knn_regression_adv.predict(test_x)\n",
    "\n",
    "# write prediction to csv file\n",
    "prediction_output = pd.DataFrame(\n",
    "    {'key': test_data.key, 'fare_amount': test_y},\n",
    "    columns = ['key', 'fare_amount'])\n",
    "prediction_output.to_csv('prediction_with_knn.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
